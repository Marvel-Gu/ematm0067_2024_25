{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b96271a-6d9f-4e10-a149-5bcee5c5fa29",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This worksheet focuses on Neural Networks. You will:\n",
    "\n",
    "- Implement your own version of a Single Layer Perceptron (SLP) to ensure you understand the details of how it works and compare it with the implementation available in `scikit-learn` to test and validate your solution.\n",
    "- Use `scikit-learn`'s implementation of Multi-Layer Perceptrons (MLP) for both classification and regression tasks, exploring how to configure and optimise these models.\n",
    "\n",
    "This is a reasonably long and difficult worksheet, but, hopefully, an interesting one. Try your best at it and don't worry if you don't get it all done. We will be posting the solutions and you can always ask about it in a different lab in future weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051fe04f-7cab-4a8a-800b-f14a248b06f9",
   "metadata": {},
   "source": [
    "**Note**: This is a challenging worksheet, and you might not finish all tasks during the lab. However, it is designed to be engaging, so do as much as you can. Remember that the solutions will be made available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d86791-69e7-4905-9a10-f74ecd3d0571",
   "metadata": {},
   "source": [
    "# 0. Preliminaries\n",
    "We firstly import NumPy and matplotlib as we will be using these throughout the worksheet. We use a function %matplotlib inline to display plots in the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c5aef-24c2-410e-800d-c0feb5621d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: import NumPy and matplotlib here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8644d0-7348-4d04-9e33-e652b1152f81",
   "metadata": {},
   "source": [
    "# 1. Single Layer Perceptron  \n",
    "In this question, we will use a single layer perceptron from `sklearn` to make predictions on the **breast cancer dataset**. This is a classification problem where the aim is to classify instances as either malignant or benign based on 30 features, each representing various characteristics present in the images.\n",
    "\n",
    "In this question, you will:  \n",
    "(a) Download the dataset from `sklearn` and store the data and targets in suitable variables.  \n",
    "(b) Separate your data into a training and test split.  \n",
    "(c) (Optional) Write your own function to implement Single Layer Perceptron.   \n",
    "(d) Train a neural network classifier on the training data using the implementation from `sklearn` (`Perceptron`).  \n",
    "(e) Evaluate the performance of both models on the test data using appropriate metrics (e.g., accuracy, precision).  \n",
    "(f) Plot the confusion matrix to visualise the performance of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6729c51-388c-4894-bd64-ff59486f64b1",
   "metadata": {},
   "source": [
    "## Part (a)  \n",
    "Import the package `datasets` from `sklearn` and then load the load_breast_cancer dataset (function is `load_breast_cancer()`). Save the data into a variable `X` and the targets into a variable `Y`.  \n",
    "Take a look at the data in `X`. How many datapoints are there? How many features does each datapoint have? (Hint: use `np.shape`).  \n",
    "Take a look at the targets. Is this suitable for a classification algorithm or a regression algorithm?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295c5b4-3423-4866-b57a-104b75e9c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: import suitable packages, load the dataset, and save data and targets into variables X and Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58619ea-116d-41b8-a6bc-db5b46258040",
   "metadata": {},
   "source": [
    "## Part (b)\n",
    "\n",
    "Use the function `train_test_split` from `sklearn.model_selection` to split your data into a training set and a held-out test set. Use a test set that is 0.2 of the original dataset. Set the parameter `random_state` to 10 to help with replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed494565-04ee-45a0-a7d0-4d7e4678aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import the package train_test_split from sklearn.model_selection.\n",
    "\n",
    "# Split the dataset into Xtr, Xtest, Ytr, Ytest\n",
    "Xtr, Xtest, Ytr, Ytest=##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9432b834-43b8-4f09-b136-b33a0bfa6ee3",
   "metadata": {},
   "source": [
    "## (Optional) Part (c)  \n",
    "Recall from the lecture that a single-layer perceptron runs as follows:  \n",
    "\n",
    "**Training step**:  \n",
    "- For each training datapoint $(\\vec{x}_i)$:  \n",
    "  - Compute the linear combination $(z = \\vec{w} \\cdot \\vec{x}_i + b)$.  \n",
    "  - Pass \\(z\\) through the activation function (step function in this case) to get the predicted class $(y_{\\text{pred}})$.  \n",
    "  - Compute the error as $(e = y_i - y_{\\text{pred}})$, where $(y_i)$ is the true label.  \n",
    "  - Update the weights and bias using the perceptron learning rule:  \n",
    "    $[\n",
    "    \\vec{w} \\gets \\vec{w} + \\eta \\cdot e \\cdot \\vec{x}_i  \n",
    "    ]  \n",
    "    [\n",
    "    b \\gets b + \\eta \\cdot e\n",
    "    ]$  \n",
    "  Here, $(\\eta)$ is the learning rate.  \n",
    "\n",
    "**Prediction step**:  \n",
    "- For a given datapoint $(\\vec{x})$:  \n",
    "  - Compute the linear combination $(z = \\vec{w} \\cdot \\vec{x} + b)$.  \n",
    "  - Pass $(z)$ through the step function to obtain the class prediction.  \n",
    "\n",
    "Write function(s) to implement the training and prediction steps. Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e104c1-f00b-449f-a4cf-1cb10eb2e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, input_size, learning_rate, iterat):\n",
    "        #TODO# initialise the weights to random values and set the bias to 0\n",
    "        self.weights = ##TODO## (HINT: use np.random.rand())\n",
    "        self.bias = ##TODO## \n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterat = iterat\n",
    "\n",
    "    def activation(self, z):\n",
    "        #TODO # Write a function to implement the **step activation function**. This activation function should output return 1 if z >= 0, else 0\n",
    "        return ##TODO## \n",
    "   \n",
    "    def train(self, X, y):\n",
    "        for epoch in range(self.iterat):\n",
    "            for i in range(X.shape[0]):\n",
    "                # Calculate the linear combination\n",
    "                z = np.dot(X[i], self.weights) + self.bias\n",
    "                y_pred = self.activation(z)\n",
    "\n",
    "                #TODO# Calculate error between target and predicted values\n",
    "                error = ##TODO## \n",
    "                \n",
    "                #TODO# update the weights and bias according to the above equations\n",
    "                self.weights += ##TODO##\n",
    "                self.bias += ##TODO##\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.activation(z)\n",
    "#Train the perceptron\n",
    "input_size = Xtr.shape[1] # To pass the number of features\n",
    "perceptron1 = SingleLayerPerceptron(input_size=input_size, learning_rate=0.01, iterat=10)\n",
    "\n",
    "##TODO##  #Train the perceptron with the Train data\n",
    "perceptron1.train(Xtr, Ytr)\n",
    "\n",
    "#Test the perceptron\n",
    "my_Ypred = ##TODO##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5286105-4bbf-413a-9806-7590068ff8e8",
   "metadata": {},
   "source": [
    "## Perceptron in scikit-learn\n",
    "\n",
    "The `Perceptron` class in `scikit-learn` provides an implementation of the single-layer perceptron algorithm, modified to handle both binary and multi-class classification tasks. \n",
    "- **Activation Function**: Applies a step activation function, outputting class labels based on the linear combination of inputs and weights.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961111a-5183-4f79-9f08-3c0c167abb8e",
   "metadata": {},
   "source": [
    "## Part (d)  \n",
    "Now we can compare your implementation with the `sklearn` implementation. Firstly, import the classifier `Perceptron` from `sklearn.linear_model`. Specify relevant hyperparameters such as the learning rate and maximum iterations (same as in the model above). Fit the model on the training data and make predictions on the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8255ff-cec8-4bc2-9cd0-a49f96111b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the classifier Perceptron from sklearn.linear_model.\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Instantiate the Perceptron classifier with learning rate (eta) and max_iterations same as above. \n",
    "perceptron2 = Perceptron(\n",
    "    max_iter=10,    # Maximum number of iterations \n",
    "    eta0=0.01,        # Learning rate\n",
    "    verbose=1  \n",
    ")\n",
    "\n",
    "# Train the Perceptron on the training data\n",
    "perceptron2.fit(Xtr, Ytr)\n",
    "\n",
    "# Test the Perceptron\n",
    "Y_pred = perceptron2.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a0e126-ec77-40e1-809d-4ebc4f530957",
   "metadata": {},
   "source": [
    "## Part (e) (Optional) \n",
    "Use the built in metrics in sklearn to calculate the accuracy of your classifier on the Testing set. Compare the accuracy of the `sklearn` implementation with your custom implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3568dd-6ba8-4334-b01f-1eecba75daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "##TODO## Write your answer here\n",
    "#Evaluate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017c27b-692a-49e3-934b-e97f6d4a1734",
   "metadata": {},
   "source": [
    "## Part(f) \n",
    "Plot the confusion matrix to visualise the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0ce52-1b73-4e2f-92b2-bb830de90dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "##TODO## Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325019de-27a7-42da-81b3-a68544f02935",
   "metadata": {},
   "source": [
    "If the accuracy is low, consider increasing the maximum number of iterations and repeating the fitting and testing process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f699d15-2f7e-4343-951c-e71c23385f4f",
   "metadata": {},
   "source": [
    "# 2. Multilayer Perceptron\n",
    " <img src=\"attachment:82da26eb-a283-4bb4-a5a3-264c06e568b5.png\" width=\"400\"/>\n",
    "\n",
    "The input layer, located on the far left, contains neurons that correspond to the input features. Each neuron in the hidden layer processes the values from the previous layer through a weighted sum, which is then passed through a non-linear activation function, such as `ReLU`. Finally, the output layer takes the values from the last hidden layer and converts them into the model’s output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d08140-f53a-4683-ad61-a5b2b23181cc",
   "metadata": {},
   "source": [
    "## Pre-Written Functions in scikit-learn for MLP Classification and Regression\n",
    "\n",
    "`scikit-learn` provides pre-written implementations for neural network models through the `MLPClassifier` and `MLPRegressor` classes.\n",
    "- The `MLPClassifier` and `MLPRegressor` automatically select the appropriate configurations (e.g., loss functions and output functions) based on the problem type.\n",
    "- Users can modify hyperparameters (e.g., `hidden_layer_sizes`, `activation`, `max_iter`, etc) to tune the model for specific tasks.\n",
    "- **Note**: In other machine learning libraries, you may need to manually set the loss function and output function, as they are not always configured automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb33576-e61f-4c4d-bf7f-09c9a04af35b",
   "metadata": {},
   "source": [
    "# 2.1. Multi-class Classification using Multilayer Perceptron\n",
    "\n",
    "Now that we’ve compared how your Perceptron model performs against the `sklearn` Perceptron for binary classification, we’ll explore a multiclass classification problem using the `load_digits` dataset. This dataset involves classifying 8x8 images of handwritten digits (0–9) based on 64 pixel intensity features.\n",
    "\n",
    "In this task, you will:  \n",
    "(a) Load the dataset from `sklearn` and store the data and targets.  \n",
    "(b) Split the data into training and test sets.  \n",
    "(c) Train a neural network classifier using `MLPClassifier`.  \n",
    "(d) Evaluate your model’s performance on the test set (e.g., accuracy, precision).  \n",
    "(e) Modify your hyperparameters.  \n",
    "(f) (Optional) Plot the loss curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc6774-09ae-4be1-8a90-9215682207ec",
   "metadata": {},
   "source": [
    "## Part (a)  \n",
    "From `sklearn.datasets` load the load_digits dataset (function is `load_digits()`). Save the data into a variable `X1` and the targets into a variable `Y1`.  \n",
    "Take a look at the data in `X1`. How many datapoints are there? How many features does each datapoint have? (Hint: use `np.shape`). \n",
    "Take a look at the targets. How many classes does the output need to be classified into??  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb8182-d55a-419c-bba6-3fa39fb61e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO#  #Load the dataset\n",
    "digits=##TODO##\n",
    "X1 = ##TODO##\n",
    "Y1 = ##TODO##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfbde7a-2bfa-49ca-af6a-988d3237921c",
   "metadata": {},
   "source": [
    "Look at the images corresponding to the input. Set the value of the target as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e30b6-9a2e-4994-9b37-9e80f3f2c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 10)\n",
    "for i in range(20):\n",
    "    axes[i//10, i %10].imshow(digits.images[i], cmap='gray');\n",
    "    axes[i//10, i %10].axis('off')\n",
    "    axes[i//10, i %10].set_title(f\"PREDICT: {digits.target[i]}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bcc32-48a6-4f06-a194-2178e81ffcb8",
   "metadata": {},
   "source": [
    "## Part (b)  \n",
    "Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c83957-96db-4432-803e-a9acbe8a3197",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO##\n",
    "Xtr1, Xtest1, Ytr1, Ytest1=##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df20c4f-067a-4e31-b443-42649db54deb",
   "metadata": {},
   "source": [
    "##  MLPClassifier from `sklearn.neural_network`\n",
    "- Designed for classification tasks \n",
    "- Uses `log-loss` (also called cross-entropy loss function) by default.\n",
    "- outputs probabilities for each class by default using the **softmax** activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0d9cb-9070-4ebd-ba41-0a46700a129b",
   "metadata": {},
   "source": [
    "## Part (c)\n",
    "Import `MLPClassifier` from `sklearn.neural_network`.After importing, check the default parameters of the `MLPClassifier` model.\n",
    "\n",
    "Create an instance of the `MLPClassifier` with the following settings:\n",
    "- 2 hidden layers, each with 10 neurons.\n",
    "- activation set as ReLU  \n",
    "- Set the maximum number of iterations (`max_iter`) to 10.\n",
    "- \n",
    "Train the model using the training data (`Xtr1`,`Ytr1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddc143-a85c-409c-bdb5-c66fd19a41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,10),  \n",
    "    activation='relu',   \n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=10, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "##TODO## Train the MLPClassifier on the training data\n",
    "##TODO##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3280e-ff06-4113-bfb0-57af45cba0c7",
   "metadata": {},
   "source": [
    "## Part (d)\n",
    "Make predictions on the test set.\n",
    "Measure accuracy using sklearn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e88a6a-2a8c-404b-9cc9-7bde8ad385cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO##\n",
    "y_pred_mlp1 = ##TODO##\n",
    "accuracy_mlp1 = ##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5179ea-71ad-4e6b-91b3-0d15bd31611f",
   "metadata": {},
   "source": [
    "Visualize a sample of images and their predictions for MLP. Check if it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33713d18-5894-41ff-988a-23f97178423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ed7c9-84c1-4a62-ab61-8dba0e6cc41d",
   "metadata": {},
   "source": [
    "## Part (e)\n",
    "Experiment with Hidden Layer Configurations\n",
    "This neural network currently has 2 hidden layers, each with 10 neurons (`hidden_layer_sizes=(10,10)`). The parameter `hidden_layer_sizes=(x, y, ...)` specifies the number of neurons in each layer.\n",
    "\n",
    "- Try experimenting with different configurations of hidden layers (e.g., fewer or more layers, or varying the number of neurons per layer) to observe their effect on the model's performance.\n",
    "- Does increasing the number of layers or neurons always improve the performance? Why or why not?\n",
    "\n",
    "Investigate the Parameter `activation`\n",
    "Explore the parameter `activation` in the `MLPClassifier` model. \n",
    "\n",
    "- What are the different activation functions available (e.g., `relu`, `tanh`, `logistic`)?\n",
    "- Change the activation function and observe how it impacts the model's performance.\n",
    "\n",
    "Investigate the Parameter `learning_rate_init`\n",
    "- Explore the parameter `activation` in the `MLPRegressor` or `MLPClassifier` model. \n",
    "- What does increasing or decreasing the value of learning_rate result in?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e2249-70a9-458b-a60c-c69adea4be05",
   "metadata": {},
   "source": [
    "## Part (f) (Optional)\n",
    "Plot the loss curve (progression of the loss during training)\n",
    "Access the model's loss curve to visualise the progression of the loss during training.\n",
    "- Use the `loss_curve_` attribute of the trained model to retrieve the loss values for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d00bea-9900-4626-9007-2c82bafe26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e5a6f5-1cf7-4be4-88ec-79cde9a32eab",
   "metadata": {},
   "source": [
    "# 2.2.  Regression using Multilayer Perceptron\n",
    "Now, we’ll perform a regression task using a Multilayer Perceptron on the `load_diabetes` dataset. This dataset involves predicting a continuous target variable related to diabetes progression based on 10 numerical features.  \n",
    "\n",
    "In this task, you will:  \n",
    "(a) Load the dataset using the `load_diabetes` function from `sklearn.datasets`.  \n",
    "(b) Split the data into training and test sets.  \n",
    "(c) Train a neural network regressor using `MLPRegressor`.  \n",
    "(d) Evaluate your model’s performance on the test set using metrics such as mean squared error (MSE) and R² score.  \n",
    "(e) Experiment with different hyperparameters to optimise the model's performance.  \n",
    "(f) (Optional) Plot the predicted vs actual values to visualise the model's accuracy.  \n",
    "(g) Plot the loss curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe9a88-1dd1-4eca-b92c-0436a3c4c6bf",
   "metadata": {},
   "source": [
    "## Part (a)\n",
    "Load the load_diabetes from sklearn.datasets\n",
    "Check the X and y of your data\n",
    "Take a look at the data in `X2` and the target labels in `Y2`. Find their shapes using `.shape`. \n",
    "- How many data points are there in `X2`?\n",
    "- How many features does each data point have?\n",
    "- Does the data require scaling or normalising before training a neural network model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc722b18-eec5-497f-923a-f1cb51aa8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO# Load dataset\n",
    "[X2,Y2]=##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc0ace-30f0-450e-9ee2-c9de26d2bcb8",
   "metadata": {},
   "source": [
    "## Part (b) \n",
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04104e25-6832-4ee0-ad01-4a8cd692c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO## Split dataset\n",
    "Xtr2, Xtest2, Ytr2, Ytest2 = ##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11abbeca-f208-45c5-bbcb-ecdc3f180ca9",
   "metadata": {},
   "source": [
    "## MLPRegressor from `sklearn.neural_network`\n",
    "Class MLPRegressor from `sklearn.neural_network` implements a multi-layer perceptron (MLP) that trains using backpropagation with no activation function  in the output layer, which can also be seen as using the identity function as activation function. Therefore, it uses the square error as the loss function, and the output is a set of continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eeba41-ebff-4f5c-8ee1-e0b5d77c65f9",
   "metadata": {},
   "source": [
    "## Part (c)\n",
    "Import the `MLPRegressor` from `sklearn.neural_network`. After importing, check the default parameters of the `MLPRegressor` model.\n",
    "- What are the default values for parameters such as `hidden_layer_sizes`, `activation`, and `solver`?\n",
    "- How would you go about changing any of these default parameters for your model?\n",
    "## Create the instance of the MLPRegressor\n",
    "Create an instance of the `MLPRegressor` with the following settings:\n",
    "- 2 hidden layers, each with 10 neurons.\n",
    "- Set the maximum number of iterations (`max_iter`) to 10.\n",
    "  \n",
    "Train the model using the training data (`Xtr2`,`Ytr2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4bb5be-e131-446e-a146-1bbb5e71ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO# Import the MLPRegressor from sklearn.neural_network\n",
    "\n",
    "# Create the MLP Regressor model\n",
    "mlp_regression = ##TODO##\n",
    "\n",
    "##TODO## Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d321c29-c82b-43f4-af81-5570e938d3bf",
   "metadata": {},
   "source": [
    "## Part (d)\n",
    "Make predictions on the test set (`Xtest2`).\n",
    "Evaluate the model using appropriate metrics from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c471dc-6fa7-4166-934a-8459f4191eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO## Predict on the test set\n",
    "Y_pred_mlp2 = ##TODO##\n",
    "\n",
    "##TODO##\n",
    "#import appropriate functions \n",
    "\n",
    "mse = ##TODO##\n",
    "r2 = ##TODO##\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93017563-8d24-4ab8-a88a-17b65eb211b5",
   "metadata": {},
   "source": [
    "## Part (e)\n",
    "Experiment with Hidden Layer Configurations\n",
    "This neural network currently has 2 hidden layers, each with 10 neurons (`hidden_layer_sizes=(10,10)`). The parameter `hidden_layer_sizes=(x, y, ...)` specifies the number of neurons in each layer.\n",
    "\n",
    "- Try experimenting with different configurations of hidden layers (e.g., fewer or more layers, or varying the number of neurons per layer) to observe their effect on the model's performance.\n",
    "- Does increasing the number of layers or neurons always improve the performance? Why or why not?\n",
    "- Change the activation function and observe how it impacts the model's performance.\n",
    "-Investigate the Parameter `learning_rate_init`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa20f029-d268-4fee-b5f0-f5f4a754d700",
   "metadata": {},
   "source": [
    "## Part (f) (Optional) \n",
    "Plot the predicted vs actual values\n",
    "After training the `MLPRegressor` and predicting the outputs for `Xtest2`, create a scatter plot to compare the predicted values (`Y_pred_mlp2`) against the actual values (`Ytest2`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533102f5-7ac7-49f8-b4ff-3422714b2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO## Optionally, plot the predicted vs actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6227a7b4-2d73-4957-9a25-331d656d4d07",
   "metadata": {},
   "source": [
    "##  Part (g) Optional \n",
    "Plot the loss curve (progression of the loss during training)\n",
    "Access the model's loss curve to visualise the progression of the loss during training.\n",
    "- Use the `loss_curve_` attribute of the trained model to retrieve the loss values for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be532736-97cd-4e7e-b007-a813b9825340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve (progression of the loss during training)\n",
    "##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c0513-6104-4a84-94ac-e75d777a3476",
   "metadata": {},
   "source": [
    "# Extra\n",
    "Grid Search\n",
    "Investigate GridSearchCV from sklearn.model_selection for optimising the parameters of neural network. Apply it to both MLP classification and regression tasks using the following grid of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b27be-24cc-46b2-ad15-1a6c610b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],  # Number of neurons per layer\n",
    "    'activation': ['relu', 'logistic'],  # Activation functions\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1]  # Learning rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800acd9-c414-488f-9455-e7232a93983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO##\n",
    "\n",
    "#Classification\n",
    "grid_search1 = ##TODO##\n",
    "\n",
    "#Regression\n",
    "grid_search2 = ##TODO##\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
